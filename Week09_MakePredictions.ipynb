{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9\n",
    "# Make Predictions on NYC Taxi Data\n",
    "\n",
    "In Week 8 notebook, we have explored the content of [NYC Taxi Data](https://www.kaggle.com/c/nyc-taxi-trip-duration/data). This week, we will use numerical and graphical tools to discover the relationship between taxi trip duration and other relavent variables, so that we can make predictions on the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions to streamline data pre-processing\n",
    "- Download and unzip the data file from Kaggle.\n",
    "- Load the dataset and remove dubious records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import zipfile\n",
    "import folium\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_training_data(download_path, unzip_path):\n",
    "    \n",
    "    if os.path.exists(unzip_path + \"train.csv\"):\n",
    "        print(\"File train.csv already exists.\")\n",
    "        return\n",
    "    \n",
    "    file_name = download_path + \"nyc-taxi-trip-duration.zip\"\n",
    "    with zipfile.ZipFile(file_name, \"r\") as f:\n",
    "        f.extractall(unzip_path)\n",
    "        \n",
    "    file_name = unzip_path + \"train.zip\"\n",
    "    with zipfile.ZipFile(file_name, \"r\") as f:\n",
    "        f.extractall(unzip_path)\n",
    "        print(\"File train.csv has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the training data\n",
    "unzip_training_data(\"C:/Users/lzhao/Downloads/\", \"Data/nyctaxi/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(data_path):\n",
    "    \n",
    "    # Check if train.csv exists.\n",
    "    assert os.path.exists(data_path + \"train.csv\"), \"File train.csv does not exist.\"\n",
    "    \n",
    "    # Load train.csv as a data frame\n",
    "    raw_data = pd.read_csv(data_path + \"train.csv\", sep=',')\n",
    "    \n",
    "    # Adjust data types\n",
    "    raw_data['pickup_datetime'] = raw_data['pickup_datetime'].astype(np.datetime64)\n",
    "    raw_data['dropoff_datetime'] = raw_data['dropoff_datetime'].astype(np.datetime64)\n",
    "\n",
    "    # Remove trips that are too long or too short\n",
    "    upper_trip_limit = 7200\n",
    "    lower_trip_limit = 60\n",
    "    long_trips = raw_data[raw_data['trip_duration'] > upper_trip_limit]\n",
    "    data = raw_data.drop(long_trips.index)\n",
    "    short_trips = data[data['trip_duration'] < lower_trip_limit]\n",
    "    data = data.drop(short_trips.index)\n",
    "    \n",
    "    # Remove locations that are not in NYC.\n",
    "    data_not_nyc = data[(data['pickup_longitude'] < -74.1) | (data['pickup_longitude'] > -73.7) |\n",
    "                        (data['pickup_latitude'] < 40.5) | (data['pickup_latitude'] > 40.9) |\n",
    "                        (data['dropoff_longitude'] < -74.1) | (data['dropoff_longitude'] > -73.7) |\n",
    "                        (data['dropoff_latitude'] < 40.5) | (data['dropoff_latitude'] > 40.9)]\n",
    "    data = data.drop(data_not_nyc.index)\n",
    "    \n",
    "    # Remove irrelavent columns\n",
    "    data = data.drop(['id', 'vendor_id', 'passenger_count', 'store_and_fwd_flag', 'dropoff_datetime'], axis=1)\n",
    "    \n",
    "    print(\"Shape:\", data.shape)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "data = load_training_data(\"Data/nyctaxi/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the bivariate relationships\n",
    "Examine the relationship of a single feature and the trip duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is pick-up date time related to trip duration?\n",
    "plt.plot(data['pickup_datetime'], data['trip_duration'], 'r,', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is pick-up location related to trip duration?\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.plot(data['pickup_longitude'], data['trip_duration'], 'r,', alpha=0.05)\n",
    "ax1.set_xlabel(\"Pick-UpLongitude\")\n",
    "ax1.set_ylabel(\"Trip Duration (sec)\")\n",
    "\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax2.plot(data['pickup_latitude'], data['trip_duration'], 'r,', alpha=0.05)\n",
    "ax2.set_xlabel(\"Pick-Up Latitude\")\n",
    "ax2.set_ylabel(\"Trip Duration (sec)\")\n",
    "\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax3.plot(data['dropoff_longitude'], data['trip_duration'], 'r,', alpha=0.05)\n",
    "ax3.set_xlabel(\"Drop-OffLongitude\")\n",
    "ax3.set_ylabel(\"Trip Duration (sec)\")\n",
    "\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "ax4.plot(data['dropoff_latitude'], data['trip_duration'], 'r,', alpha=0.05)\n",
    "ax4.set_xlabel(\"Drop-Off Latitude\")\n",
    "ax4.set_ylabel(\"Trip Duration (sec)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate a numerical statistic called \"correlation coefficient\"\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Coefficient\n",
    "The **correlation coefficient** is a numerical measurement of *linear* correlation between two variables.\n",
    "- The value of correlation coefficient always lies in [-1, 1].\n",
    "- If there is a strong positive correlation, then the coefficient is close to 1.\n",
    "- If there is a strong negative correlation, then the coefficient is close to -1.\n",
    "- If there is a very weak correlation, then the coefficient is close to 0.\n",
    "- However, a near-zero coeffient may be caused by non-linear correlations.\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/d/d4/Correlation_examples2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It looks like the relationship between trip durations and other features cannot be seen directly.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "- Create additional useful features\n",
    "    - Distance between pick-up and drop-off\n",
    "    - Hour of the day\n",
    "    - Day of the week\n",
    "    - Holidays?\n",
    "    - Weather?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column representing the aerial distance between pickup and dropoff\n",
    "# Aerial distance = np.sqrt((x2 - x1) ** 2 + (y2 - y2) ** 2)\n",
    "\n",
    "def aerial_distance(record):\n",
    "    \n",
    "    return np.sqrt((record['pickup_longitude'] - record['dropoff_longitude']) ** 2 + \\\n",
    "                   (record['pickup_latitude'] - record['dropoff_latitude']) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aerial_distance(data.loc[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['aerial_distance'] = data.apply(aerial_distance, axis=1) # add axis=1 to make sure it is applied along the vertical axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hours of the day\n",
    "data['hour'] = data['pickup_datetime'].dt.hour\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of the week\n",
    "data['day'] = data['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data['hours'], data['trip_duration'], 'r,', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['day'], data['trip_duration'], 'r,', alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "\n",
    "To make predictions, data scientists need to create a **mathematical model** that explictly describe how the prediction can be computed from the data. Often times the model comes with a set of tunable parameters whose values are determined by a **training algorithm**. The field of designing models and algorithms for computers to explore relationships in a data set is called **machine learning**. It is one of the most successful approach towards building **artificial intelligence**.\n",
    "\n",
    "Today, we will employ a straight-forward strategy called **k-nearest-neighbors** to prediction trip durations for records in the test set.\n",
    "\n",
    "- For each record that requires prediction, find **k** similar records from the training set with known trip durations.\n",
    "- Since these records share similar attributes, their trips durations should be similar too.\n",
    "- Use average trip duration of the k records as the prediction for the new record.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Debo_Cheng/publication/293487460/figure/fig1/AS:651874571149316@1532430417078/An-example-of-kNN-classification-task-with-k-5.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load test.csv\n",
    "data_path = \"Data/nyctaxi/\"\n",
    "with zipfile.ZipFile(data_path + \"test.zip\", \"r\") as f:\n",
    "    f.extractall(data_path)\n",
    "    \n",
    "test_data = pd.read_csv(data_path + \"test.csv\", sep=\",\")\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of pick-up datetime\n",
    "test_data['pickup_datetime'] = test_data['pickup_datetime'].astype(np.datetime64)\n",
    "\n",
    "# Add hour of the day and day of the week\n",
    "test_data['day'] = test_data['pickup_datetime'].dt.dayofweek\n",
    "\n",
    "test_data['hour'] = test_data['pickup_datetime'].dt.hour\n",
    "\n",
    "# drop irrelavant features\n",
    "remove_cols = ['id', 'vendor_id', 'passenger_count', 'store_and_fwd_flag']\n",
    "test_data = test_data.drop(remove_cols, axis=1)\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract the first record\n",
    "test_1 = test_data.loc[[0], :]\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which record in the training data are similar to test_1?\n",
    "# How to measure similarity?\n",
    "\n",
    "# Let's use the following weighted sum of differences to measure similarity\n",
    "# similarity = differences in coordinates * 500 + difference in days of the week + difference in hours\n",
    "\n",
    "def similarity(training_record, test_record):\n",
    "    \n",
    "    diff_coordinates = np.abs(training_record['pickup_longitude'] - test_record['pickup_longitude']) + \\\n",
    "                        np.abs(training_record['pickup_latitude'] - test_record['pickup_latitude']) + \\\n",
    "                        np.abs(training_record['dropoff_longitude'] - test_record['dropoff_longitude']) + \\\n",
    "                        np.abs(training_record['dropoff_latitude'] - test_record['dropoff_latitude'])\n",
    "    \n",
    "    diff_day = np.abs(training_record['day'] - test_record['day'])\n",
    "    \n",
    "    diff_hour = np.abs(training_record['hour'] - test_record['hour'])\n",
    "        \n",
    "    return diff_coordinates * 500 + diff_day + diff_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity(data.loc[0, :], test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['similarity_test_1'] = data.apply(similarity, args=(test_1,), axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use k = 5\n",
    "# Find the 5 closes records\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
