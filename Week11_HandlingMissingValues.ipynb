{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 11\n",
    "# Data Cleaning and Preparation\n",
    "\n",
    "During the course of doing data analysis and modeling, a significant amount of time is spent on data preparation: loading, cleaning, transforming, and rearranging. Such tasks are often reported to take up 80% or more of an analyst's time. This wekk, let's study tools for missing data, duplicate data, string manipulation, and some other analytical data transformations.\n",
    "\n",
    "Reading:\n",
    "- Textbook, Chapter 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Handling Missing Values\n",
    "\n",
    "For various reasons, many real world datasets contain missing values, often encoded as blanks, NaNs or other placeholders. Such datasets are usually incompatible with the operations we want to apply to it during the analysis.\n",
    "\n",
    "In this section, we will discuss several common approaches for handling missing values:\n",
    "- Discard imcomplete records\n",
    "- Mean/median imputation\n",
    "- Hot-deck imputation\n",
    "- Missing value indicator\n",
    "- Advanced imputation methods\n",
    "\n",
    "**An Example Data Set**\n",
    "\n",
    "The [Pima Indians Diabetes Dataset](https://www.kaggle.com/uciml/pima-indians-diabetes-database) involves predicting the onset of diabetes within 5 years in Pima Indians given medical details.\n",
    "\n",
    "It is a binary (2-class) classification problem. The number of observations for each class is not balanced. There are 768 observations with 8 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "0. Number of times pregnant.\n",
    "1. Plasma glucose concentration a 2 hours in an oral glucose tolerance test.\n",
    "2. Diastolic blood pressure (mm Hg).\n",
    "3. Triceps skinfold thickness (mm).\n",
    "4. 2-Hour serum insulin (mu U/ml).\n",
    "5. Body mass index (weight in kg/(height in m)^2).\n",
    "6. Diabetes pedigree function.\n",
    "7. Age (years).\n",
    "8. Class variable (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference\n",
    "# https://machinelearningmastery.com/handle-missing-data-python/\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data set as a data frame named \"data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, we will skip some routine steps such as checking the data types or the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show value counts of the outcomes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following columns, a value of zero indicates a missing value:\n",
    "\n",
    "- Plasma glucose concentration\n",
    "- Diastolic blood pressure\n",
    "- Triceps skinfold thickness\n",
    "- 2-Hour serum insulin\n",
    "- Body mass index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should mark missing values with np.nan, so that these values can be\n",
    "# correctly ignored from operations such as sum, count, min, etc.\n",
    "cols = list(data.columns)\n",
    "cols.remove(cols[0]) # remove the preganicies column\n",
    "cols.remove(cols[-1]) # remove the outcome column\n",
    "print(cols)\n",
    "\n",
    "for col in cols:\n",
    "    for idx in data.index:\n",
    "        if data.loc[idx, col] == 0:\n",
    "            data.loc[idx, col] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How many missing values are there for each feature?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Glucose, BloodPressure, and BMI have just a few zero values, while SkinThickness and Insulin show nearly half of the rows missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Discard Rows/Columns with Missing values\n",
    "\n",
    "The simpliest strategy for handling missing data is to discard rows/columns that contain a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas provides the dropna() function that can be used to drop either columns or rows \\\n",
    "# with missing data.\n",
    "data1 = data.dropna()\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape # the size of dataset shrinked significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change axis paramter to drop columns containing missing values\n",
    "data2 = data.dropna(axis=1)\n",
    "data2.head(10) # too many useful features are removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing rows with missing values may significantly reduce the number of rows, and thus hurt the quality of dataset. This approach is only recommended if the number of missing values is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Replace Missing Values with Mean or Median\n",
    "\n",
    "The mean and median represent the \"average\" value of the column, and thus can be a reasonable guess on the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas provides fillna() function for replacing missing values with a \n",
    "# specific value.\n",
    "\n",
    "# fill the insulin column with the mean value\n",
    "data3 = data.copy() # raw_data will not be affected\n",
    "mean = data3['Insulin'].mean()\n",
    "print(mean)\n",
    "data3['Insulin'].fillna(mean, inplace=True)\n",
    "data3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform mean imputation for all columns\n",
    "data4 = data.copy()\n",
    "data4.fillna(data4.mean(), inplace=True)\n",
    "data4.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:** \n",
    "1. When is median value preferred over the mean value?\n",
    "\n",
    "For some features, median is a better indicator of the center. When there are a few extremely large values, the mean tends to be significantly larger than a typical value from the majority. Examples: income, grades, age.\n",
    "\n",
    "2. What are the limitations of mean/median imputation?\n",
    "\n",
    "    1. Imputation introduces \"fake\" values to the dataset. It might not be appropriate.\n",
    "    2. Always using mean value will make values biased towards the center. It reduces the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The standard deviations of the raw dataset\n",
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the standard deviations of the imputed dataset\n",
    "data4.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 3: Hot Deck Imputation\n",
    "**Hot deck imputation** is a method for handling missing data by replacing them with an random observed value. This imputation method preserves the variance of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Write a function that implements hot deck imputation for a column, and then\n",
    "# use apply() to apply this function to the data frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the standard deviation of imputed dataset and the original one.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Usage:**\n",
    "\n",
    "Approach 2 and 3 can be made more specific on which group each instance belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing Glucose values using the average value from people\n",
    "# of the same age.\n",
    "data = raw_data.copy()\n",
    "index = pd.isnull(data['Glucose'])\n",
    "data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the mean glucose for all the people with age 22\n",
    "data[data['Age'] == 41]['Glucose'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Glucose'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing BloodPressure value using a random value from people \n",
    "# of the same age.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 4: Add missing value indicator\n",
    "\n",
    "Sometimes the values are **not missing at random**, meaning that one cannot simply predict the missing values using existing values. If this is likely the case, then a safe approach is to add an indicator feature of whether the corresponding value is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a boolean indicating whether the insulin value is missing or not\n",
    "data = raw_data.copy()\n",
    "data['InsulinMissing'] = data['Insulin'].isnull().astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 5: Use Predictive Machine Learning Model\n",
    "\n",
    "Reference:\n",
    "- [MICEFOREST](https://github.com/AnotherSamWilson/miceforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/AnotherSamWilson/miceforest.git"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/AnotherSamWilson/miceforest.git 'C:\\Users\\lzhao\\AppData\\Local\\Temp\\pip-req-build-dck07sdu'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/AnotherSamWilson/miceforest.git to c:\\users\\lzhao\\appdata\\local\\temp\\pip-req-build-dck07sdu\n",
      "Requirement already satisfied: sklearn in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from miceforest==2.0.3) (0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from miceforest==2.0.3) (1.18.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from miceforest==2.0.3) (1.0.5)\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.11.0-py3-none-any.whl (283 kB)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from miceforest==2.0.3) (3.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from sklearn->miceforest==2.0.3) (0.23.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from pandas->miceforest==2.0.3) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from pandas->miceforest==2.0.3) (2.8.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from seaborn>=0.11.0->miceforest==2.0.3) (1.5.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->miceforest==2.0.3) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->miceforest==2.0.3) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->miceforest==2.0.3) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->miceforest==2.0.3) (2020.6.20)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->miceforest==2.0.3) (2.4.7)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->miceforest==2.0.3) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->miceforest==2.0.3) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lzhao\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->miceforest==2.0.3) (1.15.0)\n",
      "Building wheels for collected packages: miceforest\n",
      "  Building wheel for miceforest (setup.py): started\n",
      "  Building wheel for miceforest (setup.py): finished with status 'done'\n",
      "  Created wheel for miceforest: filename=miceforest-2.0.3-py3-none-any.whl size=27133 sha256=181dd6e74cd372886502a26050852d546752c9ff22c90ae0b965e9987f5736a1\n",
      "  Stored in directory: C:\\Users\\lzhao\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-o8ojuah5\\wheels\\42\\73\\11\\99af38bd0099fa95a8011ddba41feca47e12a7e279ef1db619\n",
      "Successfully built miceforest\n",
      "Installing collected packages: seaborn, miceforest\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.10.1\n",
      "    Uninstalling seaborn-0.10.1:\n",
      "      Successfully uninstalled seaborn-0.10.1\n",
      "Successfully installed miceforest-2.0.3 seaborn-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install miceforest\n",
    "# This the command below if the first one does not work:\n",
    "# !pip install git+https://github.com/AnotherSamWilson/miceforest.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data and introduce missing values\n",
    "iris = pd.concat(load_iris(as_frame=True,return_X_y=True),axis=1)\n",
    "iris['target'] = iris['target'].astype('category')\n",
    "iris_amp = mf.ampute_data(iris,perc=0.25,random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kernel. \n",
    "kds = mf.KernelDataSet(\n",
    "  iris_amp,\n",
    "  save_all_iterations=True,\n",
    "  random_state=1991\n",
    ")\n",
    "\n",
    "# Run the MICE algorithm for 3 iterations\n",
    "kds.mice(3)\n",
    "\n",
    "# Return the completed kernel data\n",
    "completed_data = kds.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.0               3.5                1.4               0.2   \n",
       "1                  4.4               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.1   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.3               3.0                5.1               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "    target  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
