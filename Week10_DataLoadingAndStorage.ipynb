{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10\n",
    "# Data Loading and Storage\n",
    "\n",
    "Accessing data is a necessary first step for most data science projects. From this chapter we will learn:\n",
    "- Reading and writing data in text format (.txt, .csv, .json)\n",
    "- Reading data from webpages (web scrapping)\n",
    "- Reading and writing data in binary format (.pickle, .feather, .h5)\n",
    "- Interacting with databases\n",
    "\n",
    "Reading:\n",
    "- Textbook, Chapter 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Reading and Writing Data in Text Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's create a data frame first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "values = np.array([\n",
    "    [100, 80, 95, 'A'],\n",
    "    [55, 60, 45, 'F'],\n",
    "    [70, 75, 90, 'A'],\n",
    "    [75, 70, 60, 'D'],\n",
    "    [60, 73, 75, 'C'],\n",
    "    [72, 63, -1, 'NA']\n",
    "])\n",
    "df = pd.DataFrame(values,\n",
    "                   columns=['Midterm', 'Project', 'Final', 'LetterGrade'],\n",
    "                   index=['Alex', 'Bob', 'Chris', 'Doug', 'Eva', \"Frank\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a csv file using .to_csv()\n",
    "import os\n",
    "print('Does path \"Data/temp/\" exist?', os.path.exists(\"Data/temp/\"))\n",
    "\n",
    "if not os.path.exists(\"Data/temp/\"):\n",
    "    os.mkdir(\"Data/temp\")\n",
    "    print('File path \"Data/temp/\" created.')\n",
    "\n",
    "df.to_csv(\"Data/temp/grades.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file\n",
    "df2 = pd.read_csv(\"Data/temp/grades.csv\", sep=\",\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the first 3 rows\n",
    "df3 = pd.read_csv(\"Data/temp/grades.csv\", sep=',', nrows=3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file, skipping row 2 and 4\n",
    "df4 = pd.read_csv(\"Data/temp/grades.csv\", sep=',', skiprows=[2, 4])\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove column headers from the csv file, then load it\n",
    "# df5 = pd.read_csv(\"Data/temp/grades.csv\", header=None, names=['Name', 'Midterm', 'Project', 'Final', 'LetterGrade'])\n",
    "df5 = pd.read_csv(\"Data/temp/grades.csv\", sep=',', names=[1, 2, 3, 4, 5])\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set first column as index\n",
    "df6 = pd.read_csv(\"Data/temp/grades.csv\", sep=',', index_col=0)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify -1 as NaN\n",
    "df7 = pd.read_csv(\"Data/temp/grades.csv\", delimiter=',', na_values=[-1])\n",
    "df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load txt file with values separated by spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/temp/values.txt\", 'w') as file:\n",
    "    file.write(\"Index Category     Value\\n\")\n",
    "    file.write(\"1            A      2.92\\n\")\n",
    "    file.write(\"2            B     12.14\\n\")\n",
    "    file.write(\"3            C    123.56\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although read_csv() is still applicable, setting delimiter to a single space will create errors\n",
    "df = pd.read_csv(\"Data/temp/values.txt\", sep=\" \")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/temp/values.txt\", sep=\"\\s+\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load JSON files\n",
    "\n",
    "**JavaScript Object Notation (JSON)** is a popular file format to storing unstructured data because it is easy for both human and computer to understand.\n",
    "- Its structure is very similar to Python dictionary\n",
    "- Load a json file with json.loads()\n",
    "- Writes to a json file with json.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "{\"name\": \"Wes\",\n",
    " \"places_lived\": [\"United States\", \"Spain\", \"Germany\"],\n",
    " \"pet\": null,\n",
    " \"siblings\": [{\"name\": \"Scott\", \"age\": 30, \"pets\": [\"Zeus\", \"Zuko\"]},\n",
    "              {\"name\": \"Katie\", \"age\": 38,\n",
    "               \"pets\": [\"Sixes\", \"Stache\", \"Cisco\"]}]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "result = json.loads(obj)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asjson = json.dumps(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use json.dump(object, file) to write the content to file\n",
    "with open(\"Data/temp/People.json\", 'w') as file:\n",
    "    json.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from People.json\n",
    "with open(\"Data/temp/People.json\", \"r\") as file:\n",
    "    people = json.load(file)\n",
    "people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the content as a data frame\n",
    "siblings = pd.DataFrame(result['siblings'], columns=['name', 'age', 'pets'])\n",
    "siblings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Web Scrapping\n",
    "When performing data science tasks, it's common to want to use data found on the internet. You'll usually be able to access the data in csv format, or via an Application Programming Interface (API). However, there are times when the data you want can only be accessed as part of a web page. In cases like this, you'll want to use a technique called **web scraping** to get the data from the web page into a format you can work with in your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a webpage\n",
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page #2** status code usually means successful download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what is downloaded\n",
    "print(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **beautifulsoup** library to extract useful information from the html script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the children attribute to select all the top-level tags\n",
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of each children\n",
    "print([type(item) for item in list(soup.children)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the html tag and its children by taking the third item in the list:\n",
    "html = list(soup.children)[2]\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('\\n'.join([str(idx) + ':\\n' + str(item) \\\n",
    "                 for idx, item in enumerate(list(html.children))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(list(html.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([type(item) for item in list(html.children)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]\n",
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(body.children))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[1]\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FInding all instances of a tag at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the first instance of a tag\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for tags by class and id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at another webpage with classes and id's\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all tags of a class\n",
    "soup.find_all(class_=\"outer-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading the weather data\n",
    "1. Open the [weather forecast page](https://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.Xbc5aXVKhhE)\n",
    "2. Display the source code (On Chrome use \"Developer Tools\")\n",
    "3. Identify the item containing data (On Chrome right click the values and select \"Inspect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"https://forecast.weather.gov/MapClick.php?lat=40.7146&lon=-74.0071#.Xbc5aXVKhhE\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "# print(len(seven_day))\n",
    "# print(seven_day)\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "# print(len(forecast_items))\n",
    "# print(forecast_items)\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find today's weather\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find weather forecast for the week\n",
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the weather data as a data frame\n",
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "    \"period\": periods,\n",
    "    \"short_desc\": short_descs,\n",
    "    \"temp\": temps,\n",
    "    \"desc\":descs\n",
    "})\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numeric temperature\n",
    "temp_nums = weather[\"temp\"].str.extract(\"(?P<temp_num>\\d+)\", expand=False)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html\n",
    "weather[\"temp_num\"] = temp_nums.astype('int')\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify day temperature from night temperature\n",
    "is_night = weather[\"temp\"].str.contains(\"Low\")\n",
    "weather[\"is_night\"] = is_night\n",
    "is_night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather[is_night]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get new headlines from New York Times?\n",
    "# Get current stock prices?\n",
    "# Monitor alarms?;\n",
    "# Download files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
